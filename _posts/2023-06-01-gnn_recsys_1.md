---
title:  GNN 을 이용한 Movielens 데이터셋에서 Link prediction

excerpt: Recommendation System, Pytorch, torch-geometric  

toc : true
toc_sticky : true  

use_math: true

categories:
  - study
tags:
  - study
  - recsys
  - pytorch
  - torch-geometric
---

[Pytorch geometric](https://colab.research.google.com/drive/1xpzn1Nvai1ygd_P5Yambc_oe4VBPK_ZT?usp=sharing)
에서 Movielens 데이터셋을 이용한 GNN 튜토리얼을 제공하고 있길레 풀어보았다.

사용하는 모델은 GraphSAGE 이고, 수행하는 테스크는 Link Prediciton 이다.

# 1. Install

우선 필요한 패키지들을 설치한다.

```python
import torch
from torch import Tensor
print(torch.__version__)

# Install required packages.
import os
os.environ['TORCH'] = torch.__version__

!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html
!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html
!pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${TORCH}.html
!pip install git+https://github.com/pyg-team/pytorch_geometric.git
```


# 2. Download dataset

데이터셋을 다운받는다, movielens 100k 데이터셋이며 상호작용 10만 , 유저 600명 , 아이템 9000개 인 데이터셋이다.

```python
from torch_geometric.data import download_url, extract_zip

url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'
extract_zip(download_url(url, '.'), '.')

movies_path = './ml-latest-small/movies.csv'
ratings_path = './ml-latest-small/ratings.csv'
```

# 3. Preprocessing

다운로드 받은 데이터를 전처리한다. 

```python
from torch_geometric.data import download_url, extract_zip

url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'
extract_zip(download_url(url, '.'), '.')

movies_path = './ml-latest-small/movies.csv'
ratings_path = './ml-latest-small/ratings.csv'

movies.csv:
===========
   movieId                                       genres
0        1  Adventure|Animation|Children|Comedy|Fantasy
1        2                   Adventure|Children|Fantasy
2        3                               Comedy|Romance
3        4                         Comedy|Drama|Romance
4        5                                       Comedy

ratings.csv:
============
   userId  movieId
0       1        1
1       1        3
2       1        6
3       1       47
4       1       50

```

이 예제에서는 평점에 따른 차이는 무시하고, 연결 여부만을 보았다.

이제 이 데이터를 그래프 구조로 만들어야 한다. 이 부분은 사람마다 만들기 나름인 것 같은데

일단 예제에서 제시하는 코드는 다음과 같다.

```python
# Load the entire ratings data frame into memory:
ratings_df = pd.read_csv(ratings_path)

# Create a mapping from unique user indices to range [0, num_user_nodes):
unique_user_id = ratings_df['userId'].unique()
unique_user_id = pd.DataFrame(data={
    'userId': unique_user_id,
    'mappedID': pd.RangeIndex(len(unique_user_id)),
})
print("Mapping of user IDs to consecutive values:")
print("==========================================")
print(unique_user_id.head())
print()
# Create a mapping from unique movie indices to range [0, num_movie_nodes):
unique_movie_id = pd.DataFrame(data={
    'movieId': movies_df.index,
    'mappedID': pd.RangeIndex(len(movies_df)),
})
print("Mapping of movie IDs to consecutive values:")
print("===========================================")
print(unique_movie_id.head())

# Perform merge to obtain the edges from users and movies:
ratings_user_id = pd.merge(ratings_df['userId'], unique_user_id,
                            left_on='userId', right_on='userId', how='left')
ratings_user_id = torch.from_numpy(ratings_user_id['mappedID'].values)
ratings_movie_id = pd.merge(ratings_df['movieId'], unique_movie_id,
                            left_on='movieId', right_on='movieId', how='left')
ratings_movie_id = torch.from_numpy(ratings_movie_id['mappedID'].values)

# With this, we are ready to construct our `edge_index` in COO format
# following PyG semantics:
edge_index_user_to_movie = torch.stack([ratings_user_id, ratings_movie_id], dim=0)
assert edge_index_user_to_movie.size() == (2, 100836)

print()
print("Final edge indices pointing from users to movies:")
print("=================================================")
print(edge_index_user_to_movie)

Mapping of user IDs to consecutive values:
==========================================
   userId  mappedID
0       1         0
1       2         1
2       3         2
3       4         3
4       5         4

Mapping of movie IDs to consecutive values:
===========================================
   movieId  mappedID
0        1         0
1        2         1
2        3         2
3        4         3
4        5         4

Final edge indices pointing from users to movies:
=================================================
tensor([[   0,    0,    0,  ...,  609,  609,  609],
        [   0,    2,    5,  ..., 9462, 9463, 9503]])
```

# 4. Graph Creation

이제 torch_geometric 을 이용하여 hetrogeneous 한 그래프 데이터 구조를 만들어 낼 것이다. <br> 
이것은 여러 타입의 노드와 엣지를 가진 그래프를 의미한다. <br>
우리는 그래프의 노드들을 샘플링 할 것이기 때문에 먼저 노드들에 id 를 부여해주고, <br>
그런 다음 노드 간에 양방향 message 를 보내기 위해서 reverse edge 를 그래프에 추가해 줄 것이다. <br>
코드는 다음과 같다.

```python
from torch_geometric.data import HeteroData
import torch_geometric.transforms as T

data = HeteroData()

# Save node indices:
data["user"].node_id = torch.arange(len(unique_user_id))
data["movie"].node_id = torch.arange(len(movies_df))

# Add the node features and edge indices:
data["movie"].x =  # TODO
data["user", "rates", "movie"].edge_index = ...  # TODO

# We also need to make sure to add the reverse edges from movies to users
# in order to let a GNN be able to pass messages in both directions.
# We can leverage the `T.ToUndirected()` transform for this from PyG:

# TODO:
raise NotImplementedError

print(data)

assert data.node_types == ["user", "movie"]
assert data.edge_types == [("user", "rates", "movie"),
                           ("movie", "rev_rates", "user")]
assert data["user"].num_nodes == 610
assert data["user"].num_features == 0
assert data["movie"].num_nodes == 9742
assert data["movie"].num_features == 20
assert data["user", "rates", "movie"].num_edges == 100836
assert data["movie", "rev_rates", "user"].num_edges == 100836

HeteroData(
  user={ node_id=[610] },
  movie={
    node_id=[9742],
    x=[9742, 20],
  },
  (user, rates, movie)={ edge_index=[2, 100836] },
  (movie, rev_rates, user)={ edge_index=[2, 100836] }
)
```

여기부터 빈칸 채우기가 나오는데 공식문서의 설명과 코드 주석을 보고 TODO 를 채운다. <br>
[HetroData 클래스의 설명을 보면](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.HeteroData.html#torch_geometric.data.HeteroData) 이렇게 나와 있다.

>HeteroData tries to mimic the behavior of a regular nested Python dictionary. In addition, it provides useful functionality for analyzing graph structures, and provides basic PyTorch tensor functionalities.

```python
from torch_geometric.data import HeteroData

data = HeteroData()

# Create two node types "paper" and "author" holding a feature matrix:
data['paper'].x = torch.randn(num_papers, num_paper_features)
data['author'].x = torch.randn(num_authors, num_authors_features)

# Create an edge type "(author, writes, paper)" and building the
# graph connectivity:
data['author', 'writes', 'paper'].edge_index = ...  # [2, num_edges]
```

파이썬 딕셔너리처럼 활용할 수 있다는 부분이 중요한 것 같다. 노드와 엣지를 생성하는 예시 코드가 있으므로 <br>
이것을 보고 우리 문제의 첫 부분을 채울 수 있다. 그 다음 부분은 transforms 클래스를 활용하라고 되어 있다. <br>
이를 통해 생성한 데이터를 커스터마이즈 할 수 있다. 이 예제에선 T.ToUndirected 메소드를 사용한다. <br>
Hetrogeneous 그래프가 message passing 을 하기 위해선 이렇게 해야하는 것 같다. <br>
(물론 아닌 경우도 있겠지만.)

# 5. Edge level splits
Train / validate / Test 데이터를 분할하자. 

T.RandomLinkSplit 을 이용하여 그래프 데이터를 분할할 수 있다고 한다.

이 클래스의 parameters 는 다음과 같다.

- num_val : validation set 의 비율, 0~1 사이의 숫자를 넣으면 된다.
- num_test : 마찬가지로 test set 의 비율이다.
- is_undirected : 그래프가 undirected 인 지 체크하는 bool 타입 인자이다. 
- key : 엣지 라벨의 이름, 지정하지 않으면 연결성 여부로 이진 분류 라벨을 설정함.
- split_labels : True 로 활성화하면, positive 와 negative 를 분할하고 저장함.
- add_negative_train_samples : True로 활성화하면, negative sample 을 train data 에 포함한다.
- neg_sampling_ratio : postive 에 대한 negative sample 의 비율
- disjoint_train_ratio : 엣지 라벨에 사용할 train set 엣지의 비율, 나머지는 message passing 에 사용됨
- edge_types : 분할할 엣지의 타입 이름
- rev_edge_types : 엣지의 역방향 타입의 이름

이것을 참고하여 지시사항에 따라 빈칸을 채워보면 다음과 같다.

```python
transform = T.RandomLinkSplit(
    num_val= 0.1,  # TODO
    num_test= 0.1 ,  # TODO
    is_undirected = True ,
    split_labels = False ,
    key = 'edge_label' , 
    add_negative_train_samples= False ,  # TODO
    neg_sampling_ratio= 2,  # TODO
    disjoint_train_ratio= 0.3 ,  # TODO
    edge_types=("user", "rates", "movie"),
    rev_edge_types=("movie", "rev_rates", "user")
)
======train_data=====
HeteroData(
  user={ node_id=[610] },
  movie={
    node_id=[9742],
    x=[9742, 20],
  },
  (user, rates, movie)={
    edge_index=[2, 56469],
    edge_label=[24201],
    edge_label_index=[2, 24201],
  },
  (movie, rev_rates, user)={ edge_index=[2, 56469] }
)

=====val_data======
HeteroData(
  user={ node_id=[610] },
  movie={
    node_id=[9742],
    x=[9742, 20],
  },
  (user, rates, movie)={
    edge_index=[2, 80670],
    edge_label=[30249],
    edge_label_index=[2, 30249],
  },
  (movie, rev_rates, user)={ edge_index=[2, 80670] }
)
```

# 6. Mini-batch loaders

이제 데이터를 나눴으니 데이터로더에 넣어서 배치를 만들어주면 된다. <br>
LinkNeighborLoader 가 이 역할을 해준다고 한다. <br>

공식 문서를 참고하여 지시사항에 맞게 빈칸을 채우면 다음과 같다.

```python
from torch_geometric.loader import LinkNeighborLoader

# Define seed edges:
edge_label_index = train_data["user", "rates", "movie"].edge_label_index
edge_label = train_data["user", "rates", "movie"].edge_label

train_loader = LinkNeighborLoader(
    data= train_data ,  # TODO
    num_neighbors= [20, 10],  # TODO
    neg_sampling_ratio= 2,  # TODO
    edge_label_index=(("user", "rates", "movie"), edge_label_index),
    edge_label=edge_label,
    batch_size=128,
    shuffle=True,
)

Sampled mini-batch:
===================
HeteroData(
  user={
    node_id=[609],
    n_id=[609],
  },
  movie={
    node_id=[2756],
    x=[2756, 20],
    n_id=[2756],
  },
  (user, rates, movie)={
    edge_index=[2, 17653],
    edge_label=[384],
    edge_label_index=[2, 384],
    e_id=[17653],
    input_id=[128],
  },
  (movie, rev_rates, user)={
    edge_index=[2, 7691],
    e_id=[7691],
  }
)
```
n_id 와 e_id 는 subgraph 를 생성할 떄, 원래의 인덱스에 매핑시키기 위해 loader 가 자동으로 생성해주는 인덱스라고 한다.

여기서 궁금했던 부분은 batch_size = 128 인데 왜 edge_label 이 384 (= 3 * 128) 만큼 샘플링 되었는가이다.

이것은 요구사항에서 negative sampling 을 2:1 의 비율로 하라고 하였기 때문에 negative sample 이 포함된 수치인 것이다.


# 7. Creating a Heterogeneous Link-level GNN

```python
from torch_geometric.nn import SAGEConv, to_hetero

이제 모델을 만들고 예측을 하면 된다.

예제에서 제시하고 있는 모델 코드는 다음과 같은데,

class GNN(torch.nn.Module):
    def __init__(self, hidden_channels):
        super().__init__()

        self.conv1 = SAGEConv(hidden_channels, hidden_channels)
        self.conv2 = SAGEConv(hidden_channels, hidden_channels)

    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:
        # Define a 2-layer GNN computation graph.
        # Use a *single* `ReLU` non-linearity in-between.
        # TODO:
        x = self.conv1(x, edge_index).relu()
        x = self.conv1(x, edge_index)

        return x 

GNN 클래스는 graph-SAGE 레이어를 이용하여 모형을 구축하고 있다.  
sage 의 forward 는 디폴트 집계함수가 mean 으로 설정되어 있다. 
이 경우, 이전 단계의 임베딩과 이웃의 임베딩을 concat 하지 않고 단순 평균내어 계산한다.

# Our final classifier applies the dot-product between source and destination
# node embeddings to derive edge-level predictions:
class Classifier(torch.nn.Module):
    def forward(self, x_user: Tensor, x_movie: Tensor, edge_label_index: Tensor) -> Tensor:
        # Convert node embeddings to edge-level representations:
        edge_feat_user = x_user[edge_label_index[0]]
        edge_feat_movie = x_movie[edge_label_index[1]]

        # Apply dot-product to get a prediction per supervision edge:
        return (edge_feat_user * edge_feat_movie).sum(dim=-1)

classifier 클래스는 계산된 노드 임베딩에 대한 내적을 수행한다.
이제 이 임베딩을 확률로 변환하여, Link Prediction 을 수행하면 된다.


class Model(torch.nn.Module):
    def __init__(self, hidden_channels):
        super().__init__()
        # Since the dataset does not come with rich features, we also learn two
        # embedding matrices for users and movies:
        self.movie_lin = torch.nn.Linear(20, hidden_channels)
        self.user_emb = torch.nn.Embedding(data["user"].num_nodes, hidden_channels)
        self.movie_emb = torch.nn.Embedding(data["movie"].num_nodes, hidden_channels)

        # Instantiate homogeneous GNN:
        self.gnn = GNN(hidden_channels)

        # Convert GNN model into a heterogeneous variant:
        self.gnn = to_hetero(self.gnn, metadata=data.metadata())

        self.classifier = Classifier()

    def forward(self, data: HeteroData) -> Tensor:
        x_dict = {
          "user": self.user_emb(data["user"].node_id),
          "movie": self.movie_lin(data["movie"].x) + self.movie_emb(data["movie"].node_id),
        } 

        # `x_dict` holds feature matrices of all node types
        # `edge_index_dict` holds all edge indices of all edge types
        x_dict = self.gnn(x_dict, data.edge_index_dict)

        pred = self.classifier(
            x_dict["user"],
            x_dict["movie"],
            data["user", "rates", "movie"].edge_label_index,
        )

        return pred

최종 모델은 다음과 같이 구성되어 있다. forward 를 보면 hetrogeneous 한 노드끼리 딕셔너리로 구분하여 Graph SAGE 의
Conv 연산을 수행시키는 것을 확인할 수 있다. 이를 위해 __init__ 에서 gnn 모형을 to_hetero 메소드를 사용하여
hetrogeneous 그래프에서 연산이 가능하게 만들고 있다. 

model = Model(hidden_channels=64)

print(model)

Model(
  (movie_lin): Linear(in_features=20, out_features=64, bias=True)
  (user_emb): Embedding(610, 64)
  (movie_emb): Embedding(9742, 64)
  (gnn): GraphModule(
    (conv1): ModuleDict(
      (user__rates__movie): SAGEConv(64, 64, aggr=mean)
      (movie__rev_rates__user): SAGEConv(64, 64, aggr=mean)
    )
    (conv2): ModuleDict(
      (user__rates__movie): SAGEConv(64, 64, aggr=mean)
      (movie__rev_rates__user): SAGEConv(64, 64, aggr=mean)
    )
  )
  (classifier): Classifier()
)
```

이제 훈련을 하면 된다. 

```python
import tqdm
import torch.nn.functional as F

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Device: '{device}'")

model = model.to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

for epoch in range(1, 6):
    total_loss = total_examples = 0
    for sampled_data in tqdm.tqdm(train_loader):
        optimizer.zero_grad()

        # TODO: Move `sampled_data` to the respective `device`
        sampled_data = sampled_data.to(device)
        # TODO: Run `forward` pass of the model
        pred = model(sampled_data)
        # TODO: Apply binary cross entropy via
        # `F.binary_cross_entropy_with_logits(pred, ground_truth)`
        ground_truth = sampled_data['user', 'rates', 'movie'].edge_label 
        loss = F.binary_cross_entropy_with_logits(pred, ground_truth)

        loss.backward()
        optimizer.step()
        total_loss += float(loss) * pred.numel()
        total_examples += pred.numel()
    print(f"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}")

    Device: 'cpu'
100%|██████████| 190/190 [00:07<00:00, 26.92it/s]
Epoch: 001, Loss: 0.4515
100%|██████████| 190/190 [00:05<00:00, 32.33it/s]
Epoch: 002, Loss: 0.3556
100%|██████████| 190/190 [00:06<00:00, 27.44it/s]
Epoch: 003, Loss: 0.3336
100%|██████████| 190/190 [00:05<00:00, 32.52it/s]
Epoch: 004, Loss: 0.3236
100%|██████████| 190/190 [00:08<00:00, 23.27it/s]Epoch: 005, Loss: 0.3106
```

# 8. Evaluating a Heterogeneous Link-level GNN
5 epoch 후 검증 과정을 진행하고 있다, 매트릭은 AUC 를 사용한다.

```python
from sklearn.metrics import roc_auc_score

preds = []
ground_truths = []
for sampled_data in tqdm.tqdm(val_loader):
    with torch.no_grad():
        # TODO: Collect predictions and ground-truths and write them into
        # `preds` and `ground_truths`.
        preds.append(model(sampled_data))
        ground_truths.append(sampled_data['user', 'rates', 'movie'].edge_label)

pred = torch.cat(preds, dim=0).cpu().numpy()
ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()
auc = roc_auc_score(ground_truth, pred)
print()
print(f"Validation AUC: {auc:.4f}")


100%|██████████| 79/79 [00:01<00:00, 77.26it/s]

Validation AUC: 0.9239
```
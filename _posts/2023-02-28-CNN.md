---
title:  "Convolutional Neural Network(1)-CNN 개념 정리"

excerpt: CNN 

toc : true
toc_sticky : true  

use_math: true

categories:
  - study
tags:
  - study
  - DeepLearning
  - CNN
---
# 1. 심층 신경망
인공 신경망이란 인간이 사고하는 과정을 수학적으로 모델링하여 
만든 기계학습 모형을 의미한다.  

사람들은 개발자가 모든 경우의 수를
하나씩 입력하여 프로그램을 만들기보다는\
일련의 예제가 주어졌을 때,
이를 보고 스스로 예측해나가는 능력을 가진 솔루션을 원했다. 

인공 신경망은 사람이 사고하는 과정을 모방하였기 때문에 주어진 데이터를 학습하면서\
신경망 모형의 예측이 얼마나 정답에 가까운지를 계속 확인하고 정답과의 오차를 줄여나간다.

이러한 과정을 반복하면 모형은 예를 들어, 스스로 다음과 같은 예측 문제를 풀 수 있는 것이다.

$$Y=3X_1+5X_2-10X_3+X_4+2X_5 \quad \text{를 샘플링해서 입력하고} \quad \\ X_1=1, X_2=4, X_3=5, X_4=6, X_5=9 \text{일 때  Y 의 값을 예측?} $$

이런 경우, 우리가 사용할 수 있는  "**심층 신경망(Deep Neural Network)**"
모형은 다음과 같다. 

![mlp](https://github.com/Sodychoe/sodychoe.github.io/blob/main/assets/images/%20study/CNN/mlp.png?raw=true){: .align-center}

<div style="text-align: center;">Source : [3]</div>

위의 그림은 여러 은닉층(Hidden Layer)을 가지고 있는 심층 신경망이며 이전 층의 입력이
다음 층의 모든 유닛에게 전파된다는 점에서 완전 연결(Fully Connected) 되어있다고 한다.

모델링한 식은 간단하다. 인간의 뉴런이 특정 역치이상의 자극을 받을 때 활성화되는 것 처럼, \
데이터의 입력을 선형 함수인 행렬의 곱으로 표현하고, 뉴런이 활성화되는 여부를 비선형 함수로
표현한 것이다.

 입력 행렬 $X$, 가중치 행렬 W , 편향 벡터 $b$,  활성화 함수가 $\sigma(\cdot)$ 일 때,
 각 은닉층을 통과한 값은 $\sigma(W^tX+b)$ 가 된다. 

그럼 마지막 Hidden Layer 를 통과한 출력 값이 실제 정답과 얼마나 비슷한 지를
수치적으로 나타내는 볼록한 형태의 손실 함수(Loss Function) 를 정의하고
이를 가중치 행렬에 대해 편미분하는 \
역전파(Back Propagation, chain rule 이라고도 한다.)를 수행하여
손실 함수를 최소로 하는 **최적의 파라미터, 가중치 행렬**을 학습하는 것이 
심층 신경망의 동작 과정이라고 할 수 있다.


# 2. 심층 신경망 모형의 문제점
그런데 인간이 이미지 데이터를 인식하는 경우에도 이런 모형이
우리의 사고과정을 잘 모방한다고 할 수 있을까?

사실 심층 신경망 모형에는 몇 가지 단점들이 존재한다.

1. 오버피팅(Overfitting) 에 취약하다.
- 오버피팅은 모형이 학습을 위해서 입력된 데이터에만 과도하게 의존하는 것을 말한다.
- 이는 모형의 복잡도(파라미터의 개수) 때문에 일어나는 현상이다.
- 

2. 불필요한 계산량이 존재한다.
- 위의 심층 신경망은 완전 연결되어있다고 하였다. 그런데 꼭 완전 연결을 해야 할까?

3. 이미지가 가진 공간적인 정보를 보존하지 못한다. 

[//]: # (![sparseconnectivity]&#40;https://github.com/Sodychoe/sodychoe.github.io/blob/main/assets/images/%20study/CNN/sparseconn.png?raw=true&#41;{: .align-center})

[//]: # (<div style="text-align: center;">Source : [2]</div>)





# 3. CNN 의 개념

![conv](https://github.com/Sodychoe/sodychoe.github.io/blob/main/assets/images/%20study/CNN/conv.png?raw=true){: .align-center}

<div style="text-align: center;">Source : [2]</div>




## 3.1 Kernel

## 3.2 Pooling

## 3.3 Flatten

## 3.4 Backward

## 3.5 Summary

![convstructure]()


# 4. References

1. [모두를 위한 딥러닝 시즌 2 : Pytorch](https://deeplearningzerotoall.github.io/season2/)
2. [Deep Learning - Ian Goodfellow and Yoshua Bengio and Aaron Courville, 2016](https://www.deeplearningbook.org/)
3. [Neural Networks and Deep Learning -Michael Nielsen , 2019 ](http://neuralnetworksanddeeplearning.com/index.html) 
4. [CNN 역전파를 이해하는 가장 쉬운 방법](https://metamath1.github.io/cnn/index.html)